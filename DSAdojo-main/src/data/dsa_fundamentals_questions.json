[
  {
    "id": "fundamentals-easy-q1",
    "type": "multiple-choice",
    "question": "What does 'Big O' notation describe?",
    "options": [
      "The worst-case time complexity of an algorithm",
      "The best-case time complexity of an algorithm",
      "The average memory usage",
      "The number of lines of code"
    ],
    "correctAnswer": 0,
    "explanation": "Big O notation describes the upper bound or worst-case time complexity of an algorithm."
  },
  {
    "id": "fundamentals-easy-q2",
    "type": "fill-blank",
    "question": "An algorithm that takes the same amount of time regardless of input size has _____ time complexity.",
    "correctAnswer": "O(1)",
    "explanation": "O(1) represents constant time complexity, independent of input size."
  },
  {
    "id": "fundamentals-easy-q3",
    "type": "multiple-choice",
    "question": "Which sorting algorithm has the best average-case time complexity?",
    "options": [
      "Bubble Sort",
      "Selection Sort",
      "Merge Sort",
      "Insertion Sort"
    ],
    "correctAnswer": 2,
    "explanation": "Merge Sort has O(n log n) average-case time complexity, which is optimal for comparison-based sorting."
  },
  {
    "id": "fundamentals-easy-q4",
    "type": "drag-drop",
    "question": "Arrange these time complexities from fastest to slowest:",
    "items": ["O(1)", "O(log n)", "O(n)", "O(n²)"],
    "correctOrder": [0, 1, 2, 3],
    "explanation": "Constant time is fastest, followed by logarithmic, linear, and quadratic."
  },
  {
    "id": "fundamentals-easy-q5",
    "type": "multiple-choice",
    "question": "What is the space complexity of storing n integers in an array?",
    "options": [
      "O(1)",
      "O(log n)",
      "O(n)",
      "O(n²)"
    ],
    "correctAnswer": 2,
    "explanation": "Storing n integers requires O(n) space."
  },
  {
    "id": "fundamentals-easy-q6",
    "type": "fill-blank",
    "question": "The process of finding a specific element in a collection is called _____.",
    "correctAnswer": "searching",
    "explanation": "Searching is the fundamental operation of finding elements in data structures."
  },
  {
    "id": "fundamentals-easy-q7",
    "type": "multiple-choice",
    "question": "Which data structure follows FIFO principle?",
    "options": [
      "Stack",
      "Queue",
      "Array",
      "Linked List"
    ],
    "correctAnswer": 1,
    "explanation": "Queue follows First In, First Out (FIFO) principle."
  },
  {
    "id": "fundamentals-easy-q8",
    "type": "multiple-choice",
    "question": "What is the time complexity of accessing an element by index in an array?",
    "options": [
      "O(1)",
      "O(log n)",
      "O(n)",
      "O(n²)"
    ],
    "correctAnswer": 0,
    "explanation": "Array access by index is constant time O(1) operation."
  },
  {
    "id": "fundamentals-easy-q9",
    "type": "fill-blank",
    "question": "A _____ is a step-by-step procedure for solving a problem.",
    "correctAnswer": "algorithm",
    "explanation": "An algorithm is a defined sequence of steps to solve a computational problem."
  },
  {
    "id": "fundamentals-easy-q10",
    "type": "multiple-choice",
    "question": "Which of these is NOT a basic data structure?",
    "options": [
      "Array",
      "Linked List",
      "Binary Search",
      "Stack"
    ],
    "correctAnswer": 2,
    "explanation": "Binary Search is an algorithm, not a data structure."
  },
  {
    "id": "fundamentals-easy-q11",
    "type": "multiple-choice",
    "question": "What does it mean when we say an algorithm is 'stable'?",
    "options": [
      "It never crashes",
      "It maintains relative order of equal elements",
      "It uses constant memory",
      "It runs in linear time"
    ],
    "correctAnswer": 1,
    "explanation": "A stable algorithm maintains the relative order of equal elements after sorting."
  },
  {
    "id": "fundamentals-easy-q12",
    "type": "fill-blank",
    "question": "The maximum number of comparisons needed to find an element in a sorted array of n elements using binary search is _____.",
    "correctAnswer": "log n",
    "explanation": "Binary search has O(log n) time complexity in the worst case."
  },
  {
    "id": "fundamentals-easy-q13",
    "type": "multiple-choice",
    "question": "What is recursion?",
    "options": [
      "A loop that runs forever",
      "A function that calls itself",
      "A sorting technique",
      "A memory allocation method"
    ],
    "correctAnswer": 1,
    "explanation": "Recursion is when a function calls itself to solve smaller subproblems."
  },
  {
    "id": "fundamentals-easy-q14",
    "type": "multiple-choice",
    "question": "Which is the correct way to measure algorithm efficiency?",
    "options": [
      "Count the number of lines of code",
      "Measure actual runtime on a computer",
      "Analyze time and space complexity",
      "Count the number of variables used"
    ],
    "correctAnswer": 2,
    "explanation": "Algorithm efficiency is measured by analyzing time and space complexity."
  },
  {
    "id": "fundamentals-easy-q15",
    "type": "drag-drop",
    "question": "Match the operation with its typical time complexity in an unsorted array:",
    "items": ["Search: O(n)", "Insert at end: O(1)", "Delete by value: O(n)", "Access by index: O(1)"],
    "correctOrder": [0, 1, 2, 3],
    "explanation": "These are the standard time complexities for basic array operations."
  },
  {
    "id": "fundamentals-medium-q1",
    "type": "multiple-choice",
    "question": "What is the space complexity of merge sort?",
    "options": [
      "O(1)",
      "O(log n)",
      "O(n)",
      "O(n²)"
    ],
    "correctAnswer": 2,
    "explanation": "Merge sort requires O(n) additional space for the temporary arrays used during merging."
  },
  {
    "id": "fundamentals-medium-q2",
    "type": "code-completion",
    "question": "Complete the binary search algorithm:",
    "code": "function binarySearch(arr, target):\n    left = 0\n    right = arr.length - 1\n    \n    while left <= right:\n        mid = (left + right) // 2\n        if arr[mid] == target:\n            return mid\n        elif arr[mid] < target:\n            left = mid + _____\n        else:\n            right = mid - _____\n    return -1",
    "blanks": ["1", "1"],
    "explanation": "Binary search narrows the search space by moving left or right pointer by 1 from mid."
  },
  {
    "id": "fundamentals-medium-q3",
    "type": "fill-blank",
    "question": "The technique of breaking a problem into smaller subproblems and solving them recursively is called _____.",
    "correctAnswer": "divide and conquer",
    "explanation": "Divide and conquer is a fundamental algorithmic paradigm used in merge sort, quick sort, etc."
  },
  {
    "id": "fundamentals-medium-q4",
    "type": "multiple-choice",
    "question": "Which sorting algorithm performs best on nearly sorted data?",
    "options": [
      "Quick Sort",
      "Merge Sort",
      "Insertion Sort",
      "Heap Sort"
    ],
    "correctAnswer": 2,
    "explanation": "Insertion sort has O(n) best-case complexity and performs excellently on nearly sorted data."
  },
  {
    "id": "fundamentals-medium-q5",
    "type": "multiple-choice",
    "question": "What is the time complexity of building a heap from an unsorted array?",
    "options": [
      "O(n log n)",
      "O(n²)",
      "O(n)",
      "O(log n)"
    ],
    "correctAnswer": 2,
    "explanation": "Building a heap from an unsorted array can be done in O(n) time using the heapify operation."
  },
  {
    "id": "fundamentals-medium-q6",
    "type": "drag-drop",
    "question": "Arrange these sorting algorithms by their worst-case time complexity (best to worst):",
    "items": ["Merge Sort O(n log n)", "Quick Sort O(n²)", "Bubble Sort O(n²)", "Insertion Sort O(n²)"],
    "correctOrder": [0, 1, 2, 3],
    "explanation": "Merge sort has the best worst-case complexity, while the others have quadratic worst-case."
  },
  {
    "id": "fundamentals-medium-q7",
    "type": "fill-blank",
    "question": "An algorithm that makes the locally optimal choice at each step is called a _____ algorithm.",
    "correctAnswer": "greedy",
    "explanation": "Greedy algorithms make the best local choice hoping to find a global optimum."
  },
  {
    "id": "fundamentals-medium-q8",
    "type": "multiple-choice",
    "question": "What is the primary advantage of linked lists over arrays?",
    "options": [
      "Faster random access",
      "Better cache locality",
      "Dynamic size",
      "Less memory usage"
    ],
    "correctAnswer": 2,
    "explanation": "Linked lists can grow and shrink dynamically, unlike fixed-size arrays."
  },
  {
    "id": "fundamentals-medium-q9",
    "type": "code-completion",
    "question": "Complete the function to calculate time complexity of nested loops:",
    "code": "// What is the time complexity of this code?\nfor i = 1 to n:\n    for j = 1 to i:\n        // constant time operation\n        \n// Time complexity: O(_____)",
    "blanks": ["n²"],
    "explanation": "The inner loop runs i times for each i, resulting in 1+2+3+...+n = n(n+1)/2 = O(n²)."
  },
  {
    "id": "fundamentals-medium-q10",
    "type": "multiple-choice",
    "question": "Which data structure is best for implementing undo functionality?",
    "options": [
      "Queue",
      "Stack",
      "Array",
      "Hash Table"
    ],
    "correctAnswer": 1,
    "explanation": "Stack's LIFO property makes it perfect for undo operations - last action is undone first."
  },
  {
    "id": "fundamentals-medium-q11",
    "type": "fill-blank",
    "question": "The process of visiting each node in a tree exactly once is called tree _____.",
    "correctAnswer": "traversal",
    "explanation": "Tree traversal algorithms like inorder, preorder, and postorder visit all nodes systematically."
  },
  {
    "id": "fundamentals-medium-q12",
    "type": "multiple-choice",
    "question": "What is the average case time complexity of hash table operations?",
    "options": [
      "O(1)",
      "O(log n)",
      "O(n)",
      "O(n log n)"
    ],
    "correctAnswer": 0,
    "explanation": "Hash tables provide O(1) average case time for search, insert, and delete operations."
  },
  {
    "id": "fundamentals-medium-q13",
    "type": "multiple-choice",
    "question": "Which technique is used to handle collisions in hash tables?",
    "options": [
      "Chaining",
      "Open addressing",
      "Both chaining and open addressing",
      "Sorting"
    ],
    "correctAnswer": 2,
    "explanation": "Both chaining (using linked lists) and open addressing (probing) are used to handle hash collisions."
  },
  {
    "id": "fundamentals-medium-q14",
    "type": "drag-drop",
    "question": "Match the algorithm paradigm with its example:",
    "items": ["Divide & Conquer: Merge Sort", "Greedy: Dijkstra's Algorithm", "Dynamic Programming: Fibonacci", "Brute Force: Linear Search"],
    "correctOrder": [0, 1, 2, 3],
    "explanation": "Each paradigm has characteristic algorithms that exemplify the approach."
  },
  {
    "id": "fundamentals-medium-q15",
    "type": "fill-blank",
    "question": "The maximum height of a balanced binary tree with n nodes is approximately _____.",
    "correctAnswer": "log n",
    "explanation": "A balanced binary tree has height O(log n), ensuring efficient search operations."
  },
  {
    "id": "fundamentals-hard-q1",
    "type": "multiple-choice",
    "question": "What is the time complexity of the following recurrence relation: T(n) = 2T(n/2) + O(n)?",
    "options": [
      "O(n)",
      "O(n log n)",
      "O(n²)",
      "O(2^n)"
    ],
    "correctAnswer": 1,
    "explanation": "Using Master Theorem: T(n) = aT(n/b) + f(n) where a=2, b=2, f(n)=O(n). Since f(n) = Θ(n^log_b(a)), the complexity is O(n log n)."
  },
  {
    "id": "fundamentals-hard-q2",
    "type": "code-completion",
    "question": "Complete the analysis of this algorithm's time complexity:",
    "code": "function mysterySolution(n):\n    if n <= 1:\n        return 1\n    count = 0\n    for i = 1 to n:\n        for j = 1 to i:\n            count++\n    return count + mysterySolution(n/2)\n    \n// T(n) = T(n/2) + O(_____)\n// Overall complexity: O(_____)",
    "blanks": ["n²", "n²"],
    "explanation": "The nested loops contribute O(n²), and the recurrence T(n) = T(n/2) + O(n²) gives overall O(n²)."
  },
  {
    "id": "fundamentals-hard-q3",
    "type": "fill-blank",
    "question": "An algorithm that solves each subproblem exactly once and stores the results is using _____ programming.",
    "correctAnswer": "dynamic",
    "explanation": "Dynamic programming optimizes recursive solutions by memoizing subproblem results."
  },
  {
    "id": "fundamentals-hard-q4",
    "type": "multiple-choice",
    "question": "Which sorting algorithm has the best worst-case time complexity and is also stable?",
    "options": [
      "Quick Sort",
      "Heap Sort",
      "Merge Sort",
      "Selection Sort"
    ],
    "correctAnswer": 2,
    "explanation": "Merge Sort has O(n log n) worst-case time complexity and is stable, unlike Quick Sort and Heap Sort."
  },
  {
    "id": "fundamentals-hard-q5",
    "type": "drag-drop",
    "question": "Arrange these space complexity scenarios from least to most memory usage:",
    "items": ["Iterative algorithm: O(1)", "Recursive with memoization: O(n)", "Divide & conquer recursion: O(log n)", "Brute force with storage: O(2^n)"],
    "correctOrder": [0, 2, 1, 3],
    "explanation": "Iterative uses constant space, recursion uses call stack, memoization stores results, exponential algorithms use exponential space."
  },
  {
    "id": "fundamentals-hard-q6",
    "type": "multiple-choice",
    "question": "What is the lower bound for comparison-based sorting algorithms?",
    "options": [
      "O(n)",
      "O(n log n)",
      "O(n²)",
      "O(log n)"
    ],
    "correctAnswer": 1,
    "explanation": "The theoretical lower bound for comparison-based sorting is Ω(n log n) due to the decision tree model."
  },
  {
    "id": "fundamentals-hard-q7",
    "type": "code-completion",
    "question": "Analyze the amortized complexity of dynamic array operations:",
    "code": "// Dynamic array that doubles in size when full\nclass DynamicArray:\n    function insert(element):\n        if size == capacity:\n            // Double the capacity\n            newArray = new Array(capacity * 2)\n            copy all elements to newArray\n            capacity = capacity * 2\n        array[size] = element\n        size++\n        \n// Amortized time complexity of insert: O(_____)\n// Worst case time complexity of single insert: O(_____)",
    "blanks": ["1", "n"],
    "explanation": "While a single insert can take O(n) time when resizing, the amortized cost is O(1) due to the doubling strategy."
  },
  {
    "id": "fundamentals-hard-q8",
    "type": "fill-blank",
    "question": "The technique of solving optimization problems by breaking them into overlapping subproblems is characteristic of _____ programming.",
    "correctAnswer": "dynamic",
    "explanation": "Dynamic programming is distinguished by overlapping subproblems and optimal substructure."
  },
  {
    "id": "fundamentals-hard-q9",
    "type": "multiple-choice",
    "question": "Which of these problems is NP-Complete?",
    "options": [
      "Sorting an array",
      "Finding shortest path in a graph",
      "Traveling Salesman Problem",
      "Binary search in sorted array"
    ],
    "correctAnswer": 2,
    "explanation": "The Traveling Salesman Problem is a classic NP-Complete problem with no known polynomial-time solution."
  },
  {
    "id": "fundamentals-hard-q10",
    "type": "multiple-choice",
    "question": "What is the space complexity of quicksort in the worst case?",
    "options": [
      "O(1)",
      "O(log n)",
      "O(n)",
      "O(n²)"
    ],
    "correctAnswer": 2,
    "explanation": "In the worst case, quicksort's recursion depth can be O(n), requiring O(n) space on the call stack."
  },
  {
    "id": "fundamentals-hard-q11",
    "type": "drag-drop",
    "question": "Order these algorithmic paradigms by their typical problem-solving approach:",
    "items": ["Brute Force: Try all possibilities", "Greedy: Local optimal choices", "Divide & Conquer: Break into subproblems", "Dynamic Programming: Optimal subproblems + memoization"],
    "correctOrder": [0, 1, 2, 3],
    "explanation": "Each paradigm represents a different level of sophistication in problem-solving strategies."
  },
  {
    "id": "fundamentals-hard-q12",
    "type": "fill-blank",
    "question": "An algorithm with time complexity O(2^n) is considered to have _____ time complexity.",
    "correctAnswer": "exponential",
    "explanation": "O(2^n) represents exponential time complexity, which grows very rapidly with input size."
  },
  {
    "id": "fundamentals-hard-q13",
    "type": "multiple-choice",
    "question": "Which technique can convert a recursive algorithm to iterative?",
    "options": [
      "Using a stack to simulate recursion",
      "Using dynamic programming",
      "Using memoization",
      "All of these"
    ],
    "correctAnswer": 3,
    "explanation": "All these techniques can help convert recursive algorithms to iterative ones or optimize them."
  },
  {
    "id": "fundamentals-hard-q14",
    "type": "code-completion",
    "question": "Complete the Master Theorem application:",
    "code": "// Given recurrence: T(n) = 4T(n/2) + O(n)\n// Master Theorem: T(n) = aT(n/b) + f(n)\n// Here: a = _____, b = _____, f(n) = O(n)\n// n^log_b(a) = n^log_2(4) = n^_____\n// Since f(n) < n^log_b(a), complexity is O(_____)",
    "blanks": ["4", "2", "2", "n²"],
    "explanation": "Using Master Theorem: a=4, b=2, so n^log_2(4) = n². Since O(n) < O(n²), the complexity is O(n²)."
  },
  {
    "id": "fundamentals-hard-q15",
    "type": "multiple-choice",
    "question": "What is the key insight behind using a hash table for O(1) average case operations?",
    "options": [
      "Data is stored in sorted order",
      "Hash function maps keys to array indices",
      "Elements are stored as linked lists",
      "Binary search is used internally"
    ],
    "correctAnswer": 1,
    "explanation": "Hash tables achieve O(1) average case by using hash functions to directly compute array indices from keys."
  }
]